from flask import Flask, request, jsonify
from flask_cors import CORS
from services import buscar_gene_pkd1, realizar_alinhamento_grande
import sys
import requests
import os
import json
import time

app = Flask(__name__)
CORS(
    app,
    supports_credentials=True,
    resources={r"/*": {"origins": "http://localhost:5173"}}
)

# Rotas b√°sicas de status / sa√∫de para evitar 404 no root e permitir monitoramento
@app.route('/', methods=['GET'])
def raiz():
    return jsonify({
        "status": "ok",
        "service": "back-end-fasta",
        "endpoints": [
            "/buscar-pkd1 (POST multipart: arquivo)",
            "/dados-analise (GET)",
            "/health (GET)"
        ]
    })

@app.route('/health', methods=['GET'])
def health():
    return jsonify({"status": "ok"})

# Vari√°vel global para armazenar o √∫ltimo resultado da an√°lise
ultimo_resultado_analise = {}

def sanitize_sequence(seq: str, max_len: int = 400):
    if not seq:
        return "(sequ√™ncia vazia)"
    seq = seq.strip().upper()
    if len(seq) <= max_len:
        return seq
    return seq[:max_len] + f"... (total {len(seq)} nt)"

def generate_llm_summary(dados: dict) -> str:
    """Gera um resumo textual usando Gemini (quando habilitado).

    Requisitos:
      - ENABLE_LLM=true
      - GEMINI_API_KEY definido
    Fallback: retorna texto padr√£o se n√£o configurado ou em erro.
    """
    if os.getenv("ENABLE_LLM", "false").lower() != "true":
        return "Resumo LLM desativado (ENABLE_LLM != true)."

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        return "Resumo LLM indispon√≠vel: GEMINI_API_KEY n√£o configurada."

    # Monta prompt estruturado
    identidade = dados.get("identidade") or "N/D"
    score = dados.get("score") or "N/D"
    classificacao = dados.get("classificacao") or "N/D"
    confianca = dados.get("confianca") or "N/D"
    exon_seq = sanitize_sequence(dados.get("exon29_amostra"))

    prompt = f"""
Voc√™ √© um assistente especializado em gen√©tica veterin√°ria.
Gere um relat√≥rio cl√≠nico interpretativo em portugu√™s claro sobre o gene PKD1 (exon29) para felinos.
Inclua se√ß√µes: 1) Vis√£o Geral, 2) Interpreta√ß√£o do Alinhamento, 3) Classifica√ß√£o do Modelo, 4) Risco / Implica√ß√µes, 5) Pr√≥ximos Passos Recomendados.
Use bullets quando apropriado. Evite prometer diagn√≥stico definitivo.

Dados:
- Identidade do alinhamento: {identidade}
- Score bruto do alinhamento: {score}
- Classifica√ß√£o do modelo (interno): {classificacao}
- Confian√ßa do modelo: {confianca}
- Trecho exon29 analisado (parcial/truncado se grande): {exon_seq}

Produza texto objetivo (m√°x ~450 palavras), mantendo tom profissional e acess√≠vel a veterin√°rio.
""".strip()

    # Endpoint b√°sico Gemini generative (v1beta) - model gemini-pro (ajust√°vel)
    url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent"
    headers = {"Content-Type": "application/json"}
    payload = {
        "contents": [
            {"parts": [{"text": prompt}]}
        ]
    }

    try:
        start = time.time()
        resp = requests.post(f"{url}?key={api_key}", headers=headers, data=json.dumps(payload), timeout=25)
        dur = time.time() - start
        if resp.status_code != 200:
            return f"Falha ao gerar resumo LLM (HTTP {resp.status_code}) em {dur:.1f}s"
        data = resp.json()
        # Estrutura t√≠pica: data['candidates'][0]['content']['parts'][0]['text']
        candidates = data.get('candidates') or []
        if not candidates:
            return "Resposta LLM vazia ou sem candidatos."
        parts = candidates[0].get('content', {}).get('parts') or []
        if not parts:
            return "Resposta LLM sem partes de texto."
        texto = parts[0].get('text', '').strip()
        return texto or "Resposta LLM vazia."
    except Exception as e:
        return f"Erro ao contatar LLM: {e}"  # Fallback amig√°vel

def print_progress(progress, message=None):
    bar_length = 40
    block = int(round(bar_length * progress))
    text = f"\r[{'#' * block}{'-' * (bar_length - block)}] {progress:.1%}"
    if message:
        text += f" | {message}"
    sys.stdout.write(text)
    sys.stdout.flush()

@app.route('/buscar-pkd1', methods=['POST'])
def buscar_pkd1():
    global ultimo_resultado_analise

    if 'arquivo' not in request.files:
        return jsonify({"error": "Nenhum arquivo foi enviado"}), 400

    arquivo = request.files['arquivo']
    conteudo = arquivo.stream.read().decode('utf-8').splitlines()

    def update_progress(progress, message):
        print_progress(progress, message)

    print("üìÅ Processando arquivo...")
    gene_info = buscar_gene_pkd1(conteudo)
    if 'error' in gene_info:
        return jsonify(gene_info)

    print("\nüî¨ Executando alinhamento...")
    alinhamento_result = realizar_alinhamento_grande(
        gene_info['sequencia'],
        progress_callback=update_progress
    )

    # Se houve erro no alinhamento, retorna com 422 (processamento)
    if isinstance(alinhamento_result, dict) and 'error' in alinhamento_result:
        return jsonify(alinhamento_result), 422

    gene_info['alinhamento_result'] = alinhamento_result
    print("\n‚úÖ Processo conclu√≠do!")

    # Exibe no terminal: exon29 e similaridade (se dispon√≠vel)
    print("\nüß¨ Sequ√™ncia extra√≠da do exon29:", flush=True)
    print(alinhamento_result.get('exon29_amostra', 'N/D'), flush=True)

    melhor = alinhamento_result.get('melhor_alinhamento', {})
    if 'score' in melhor:
        print(f"\nüìè Similaridade do alinhamento: {melhor['score']:.2f}")

    # Disponibiliza dados para /dados-analise imediatamente ap√≥s alinhamento
    try:
        global ultimo_resultado_analise
        ultimo_resultado_analise = {
            "identidade": melhor.get("identidade"),
            "score": melhor.get("score"),
            "classificacao": None,
            "confianca": None,
        }
    except Exception:
        pass

    # Envia o exon29 para a IA (classificador interno)
    ia_host = os.getenv("IA_HOST", "ia")  # usar nome do servi√ßo no docker compose
    outra_api_url = f"http://{ia_host}:6000/classificar-exon29"
    try:
        response = requests.post(
            outra_api_url,
            json={"alinhamento_result": {"exon29_amostra": alinhamento_result.get('exon29_amostra', '')}}
        )
        if response.status_code != 200:
            print(f"\n‚ùå Erro ao enviar para a IA: {response.status_code} - {response.text}")
        else:
            resultado_ia = response.json()
            print("\nü§ñ Resposta da IA:")
            print(f"üìå Classifica√ß√£o: {resultado_ia['classificacao']}")
            print(f"üìä Confian√ßa: {resultado_ia['confianca']}")
            gene_info["classificacao_ia"] = resultado_ia

            # Salva as informa√ß√µes importantes para a nova rota
            try:
                ultimo_resultado_analise.update({
                    "classificacao": resultado_ia.get("classificacao"),
                    "confianca": resultado_ia.get("confianca"),
                })
            except Exception:
                pass

    except Exception as e:
        print(f"\n‚ùå Erro ao conectar com a IA: {e}")

    # Gera√ß√£o de resumo LLM (opcional)
    try:
        contexto_llm = {
            "identidade": ultimo_resultado_analise.get("identidade"),
            "score": ultimo_resultado_analise.get("score"),
            "classificacao": ultimo_resultado_analise.get("classificacao"),
            "confianca": ultimo_resultado_analise.get("confianca"),
            "exon29_amostra": alinhamento_result.get('exon29_amostra')
        }
        resumo_texto = generate_llm_summary(contexto_llm)
        ultimo_resultado_analise["relatorio_texto"] = resumo_texto
        gene_info["relatorio_texto"] = resumo_texto
    except Exception as e:
        ultimo_resultado_analise["relatorio_texto"] = f"Falha ao gerar resumo: {e}"
        gene_info["relatorio_texto"] = ultimo_resultado_analise["relatorio_texto"]

    return jsonify(gene_info)

@app.route('/dados-analise', methods=['GET'])
def dados_analise():
    if not ultimo_resultado_analise:
        return jsonify({"error": "Nenhuma an√°lise foi realizada ainda"}), 404
    return jsonify(ultimo_resultado_analise)

@app.route('/resumo-analise', methods=['GET'])
def resumo_analise():
    if not ultimo_resultado_analise:
        return jsonify({"error": "Nenhuma an√°lise foi realizada ainda"}), 404
    texto = ultimo_resultado_analise.get("relatorio_texto")
    if not texto:
        return jsonify({"status": "pendente"})
    return jsonify({"relatorio_texto": texto})

if __name__ == '__main__':
    print("üß¨ Servidor de An√°lise Gen√©tica rodando em http://localhost:5000/buscar-pkd1")
    app.run(host='0.0.0.0', port=5000, debug=True)
